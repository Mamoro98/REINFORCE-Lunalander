

# ğŸš€ LunarLander REINFORCE ğŸª

Welcome to the **LunarLander REINFORCE** project! This repository demonstrates the implementation of a reinforcement learning (RL) agent using the REINFORCE algorithm to control a lunar lander. ğŸŒ•âœ¨

## ğŸ“š Project Overview
This project trains an RL agent to:
1. Land the lunar module safely using optimal actions. ğŸŒŸ
2. Maximize cumulative rewards over episodes. ğŸ¯
3. Improve performance using policy gradients and neural networks. ğŸ§ 

## ğŸ”§ Key Features
- **Environment:** LunarLander-v3 from Gymnasium. ğŸ®
- **Algorithm:** REINFORCE (Monte Carlo Policy Gradient). ğŸ“ˆ
- **Frameworks:** Built with `JAX`, `Haiku`, and `Optax` for high-performance computation. âš¡
- **Visualization:** Tracks and plots rewards over episodes. ğŸ“Š

## ğŸ› ï¸ Setup Instructions
### 1ï¸âƒ£ Install Dependencies
Run the following commands to install required libraries:
```bash
pip install jax jaxlib dm-haiku gymnasium matplotlib optax
```

### 2ï¸âƒ£ Run the Code
Launch the training process:
```bash
python lunalander.py
```

### 3ï¸âƒ£ Visualize Results
Check the plot of cumulative rewards at the end of training. ğŸ“‰â¡ï¸ğŸ“ˆ

## ğŸ§  How It Works
1. **Policy Neural Network**: A multi-layer perceptron predicts action probabilities. ğŸ–¥ï¸
2. **Policy Gradient Updates**: Improves the policy to maximize rewards. ğŸ”„
3. **Discounted Returns**: Calculates future rewards at each timestep. â³

## ğŸ“Š Results
After training for ~8000 episodes, the agent learns to land successfully with high returns. Check out the final performance metrics and plots! ğŸ‰
Video : https://github.com/user-attachments/assets/a42812e7-8887-4938-8646-8394b82e607e


## ğŸ¯ Future Enhancements
- Experiment with different network architectures. ğŸ› ï¸
- Apply to other environments like CartPole or BipedalWalker. ğŸ¤–
- Explore baseline variance reduction techniques. ğŸ”¬

## ğŸ¤ Contributing
Contributions are welcome! Feel free to submit a pull request or open an issue. ğŸ“

## ğŸ“ Credits
- Adapted from **Deep Learning Indaba 2022** and **AIMS South Africa** workshops. ğŸŒ
- Special thanks to Arnu Pretorius and the AIMS team. ğŸ¤

---

Would you like to add any specific details or refine it further?
